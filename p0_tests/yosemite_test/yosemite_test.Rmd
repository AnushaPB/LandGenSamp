---
title: "yosemite_test"
output: html_document
---
```{r}
library("here")
library("vcfR")
library("doParallel")
```

```{r}
adaptive_loci <- c(207, 231, 304, 325, 435, 618, 649, 697, 772, 978)+1

s <- sample(10000,2000,replace = FALSE)
gsd_df <- read.csv(here("yosemite_test","mod-yosemite_demo_it--1_t-500_spp-Sceloporus graciosus.csv"))
gsd_df$tmp <- as.numeric(stringr::str_extract(gsd_df$e, '(?<=\\[)[^,]+(?=,)'))
gsd_df$sdm <- as.numeric(stringr::str_extract(gsd_df$e, '(?<=, )[^,]+(?=,)'))
gsd_df$ppt <- as.numeric(stringr::str_extract(gsd_df$e, '(?<=, )[^,]+(?=\\])'))
gsd_df$z <- as.numeric(gsub("\\[|\\]", "", gsd_df$z))
rownames(gsd_df) <- gsd_df$idx
#gsd_df <- gsd_df[s,]
head(gsd_df)

vcf <- read.vcfR(here("yosemite_test","mod-yosemite_demo_it--1_t-500_spp-Sceloporus graciosus.vcf"))
x <- vcfR2genlight(vcf)
gen <- as.matrix(x)
#gen <- gen[s,]
dim(gen)
```

```{r}

set.seed(42)

#number of points to sample
npts <- c(36, 81, 144, 225, 324)

for(n in npts){
  samples <- foreach(i =1, .combine=rbind) %dopar% {
    #take random sample
    samples <- gsd_df[sample(1:nrow(gsd_df), n), "idx"]
    #return vector of sample IDs
    return(samples)
    
  }
  #bind sample IDs together and export (rows are parameter sets/columns are individual IDs)
  write.csv(samples, paste0("outputs/samples_rand",n,".csv"), row.names = FALSE)
}



```

```{r}

envgeo_samp <- function(pts, npts, Nreps = 1000){
  Nreps <- 1000
  sample.sets <- matrix(nrow=Nreps, ncol=npts)
  results <- data.frame(env1.var=numeric(Nreps), env2.var=numeric(Nreps),
                        Mantel.r=numeric(Nreps), Mantel.p=numeric(Nreps),
                        mean.dist=numeric(Nreps))
  
  env.df <- gsd_df[,c("tmp","sdm")]
  e.dist <-  as.matrix(dist(gsd_df[,c("tmp","sdm")], diag = TRUE, upper = TRUE)) 
  g.dist <- as.matrix(dist(gsd_df[,c("x","y")], diag = TRUE, upper = TRUE))
  for(i in 1:Nreps){
    NN <- sample(1:nrow(gsd_df), npts, replace = FALSE)
    sample.sets[i,] <- NN
    
    env.sub <- env.df[NN,]
    g.dist.sub <- g.dist[NN, NN]
    e.dist.sub <- e.dist[NN, NN]
    
    results$mean.dist[i] <- mean(g.dist.sub)
    
    results$env1.var[i] <- var(env.sub$tmp)
    results$env2.var[i] <- var(env.sub$sdm)
    
    DxE <- mantel(g.dist.sub, e.dist.sub, permutations = 99)
    results$Mantel.r[i] <- DxE$statistic
    results$Mantel.p[i] <- DxE$signif
  }
  
  score <- scale(1-results$Mantel.r) + scale(results$env1.var) + scale(results$env2.var)
  best_sample <- sample.sets[which.max(score),]
  sub_df <- gsd_df[best_sample,]
  
  #save IDs to vector
  samples <- as.character(sub_df$idx)
  
  return(samples)
}


for(n in npts){
  samples <- foreach(i=1, .combine=rbind) %dopar% {
    library("here")
    library("vegan")
    
    pts <- gsd_df[,c("idx","x","y")]
    samples <- envgeo_samp(pts, npts = n, Nreps = 1000)
    
    #return vector of sample IDs
    return(samples)
    
  }
  
  write.csv(samples, paste0("outputs/samples_envgeo",n,".csv"), row.names = FALSE)
}


  
```


```{r}
ldim=90

grid_samp <- function(pts, npts, ldim){
  inc <- ldim/sqrt(npts)
  xgrid <- ygrid <- seq(0, ldim, inc) 
  subs <- c()
  #first round of sampling: entire grid
  for(i in 1:(length(xgrid)-1)){ 
    for(j in 1:(length(ygrid)-1)){ 
      gridsq = subset(pts, y > ygrid[j] & y < ygrid[j+1] & x > xgrid[i] & x < xgrid[i+1]) 
      if(dim(gridsq)[1]>0){ subs = rbind(subs, gridsq[sample(1:dim(gridsq)[1],1 ), ]) }
    } 
  }
  #reset grid indices
  i=1
  j=1
  #second round of sampling: cycle through gridcells again until number of desired samples is reached
  while(nrow(subs) != npts & i < (length(xgrid)-1) & j < (length(ygrid)-1)){
    i = i+1
    j = j+1
    gridsq = subset(pts, y > ygrid[j] & y < ygrid[j+1] & x > xgrid[i] & x < xgrid[i+1]) 
    if(dim(gridsq)[1]>0){subs = rbind(subs, gridsq[sample(1:dim(gridsq)[1],1 ), ])}
  }
  
  plot(gsd_df$x, gsd_df$y, pch=19, cex=0.2, col="gray", main = npts)
   
  points(subs$x, subs$y, col=i+1)
   
  #save IDs to vector
  samples <- as.character(subs$idx)
  
  return(samples)
}

for(n in npts){
  samples <- foreach(i=1,combine=rbind) %dopar% {
      
      pts <- gsd_df[,c("idx","x","y")]
      samples <- grid_samp(pts, npts = n, ldim = ldim)
    
    #return vector of sample IDs
    return(samples)
    
  }
  
  
  write.csv(samples, paste0("outputs/samples_grid",n,".csv"), row.names = FALSE)
}

```

```{r}


transect_samp <- function(pts, npts, ytsct, buffer){
  #pts - dataframe with IDs and coords
  #npts - total number of points to sample (evenly split across transects)
  #buffer - buffer around transects within which points are sampled 
  
  #divide number of samples evenly among the transects
  npts_tsct <- npts/length(ytsct)
    
  #plot all points (gray) (for debugging, comment out later)
  par(pty="s")
  plot(gsd_df$x, gsd_df$y, pch=19, cex=0.2, col="gray", main = npts)
    
  #create empty vector to store IDs
  samples <- c()
  for(i in 1:length(ytsct)){ 
    #subset points around transect based on buffer
    tsctsq <- subset(pts, y > (ytsct[i] - buffer) & y < (ytsct[i] + buffer))
    #randomly sample subset of transect points to match number of samples needed for each transect
    tsctsq <- tsctsq[sample(nrow(tsctsq), npts_tsct),]
    #plot points sampled (for debugging, comment out later)
    points(tsctsq$x, tsctsq$y, col=i+1)
    #store IDs in list
    samples <- c(samples, tsctsq$idx)
  }
  
  #confirm correct number of samples were subsetted
  stopifnot(npts == length(samples))
  
  #return vec of sample IDs
  return(samples)
}

#horizontal transects (y-coords)
ytsct <- c(10, 20, 30)*2
#buffer around transects
#NOTE: changed from 1 to 2 because a buffer of 2 did not include enough points
buffer <- 2


for(n in npts){
  samples <- foreach(i=1, .combine=rbind) %dopar% {
      pts <- gsd_df[,c("idx","x","y")]
      samples <- transect_samp(pts, n, ytsct, buffer)
    
    #return vector of sample IDs
    return(samples)
    
  }
  
  write.csv(samples, paste0("outputs/samples_trans",n,".csv"), row.names = FALSE)
}
```

```{r}

##########
#  LFMM  #
##########


run_lfmm_full <- function(gen, gsd_df, loci_df){
  #get adaptive loci
  loci_trait1 <- loci_df$trait1 + 1 #add one to convert from python to R indexing
  loci_trait2 <- loci_df$trait2 + 1 #add one to convert from python to R indexing
  adaptive_loci <- c(loci_trait1, loci_trait2)
  neutral_loci <- c(1:nloci)[-adaptive_loci]
  
  #PCA to determine number of latent factors
  pc <- prcomp(gen)
  par(pty="s",mfrow=c(1,1))
  eig <- pc$sdev[1:100]^2
  #estimate number of latent factors using quick.elbow (see general functions for description of how this function works)
  #this is a crude way to determine the number of latent factors that is based on an arbitrary "low" value 
  #(low defaults to 0.08, but this was too high imo so I changed it t0 0.05)
  K <- quick.elbow(eig, low = 0.05, max.pc = 0.9)
  plot(eig, xlab = 'PC', ylab = "Variance explained")
  abline(v = K, col= "red", lty="dashed")
  

  #gen matrix
  genmat = as.matrix(gen)
  #env matrix
  env1mat = as.matrix(gsd_df$tmp)
  
  #ENV1
  #run model
  lfmm_mod <- lfmm_ridge(genmat, env1mat, K = K)
  #performs association testing using the fitted model:
  pv <- lfmm_test(Y = genmat, 
                  X = env1mat, 
                  lfmm = lfmm_mod, 
                  calibrate = "gif")
  #adjust pvalues
  pvalues <- data.frame(env1=p.adjust(pv$calibrated.pvalue[,1], method="fdr"))
  #env1 candidate loci
  #Identify LFMM cand loci
  lfmm_loci1 <- which(pvalues[,1] < 0.05) 
  #calc True Positive Rate
  TP <- sum(lfmm_loci1 %in% adaptive_loci)
  TPR1 <- TP/length(adaptive_loci)
  #calc False Discovery Rate 
  FD <- sum(lfmm_loci1 %in% neutral_loci) 
  FDR1 <- FD/(FD + TP)
  
  #PLOT TO CHECK RESULTS (for debugging, remove later)
  
  par(mfrow=c(1,2))
  plot(-log10(pvalues[,1]), 
       pch = 19, 
       cex = .2, 
       xlab = "SNP", ylab = "-Log P",
       col = "grey",
       main = "env1")
  points(adaptive_loci, 
         -log10(pvalues[,1])[adaptive_loci], 
         col = "red", 
         cex = 1.5)
  abline(h = -log10(0.05), col="red", lty=2)
  
  
  return(data.frame(K = K,
                    TPR1 = TPR1, FDR1 = FDR1))
}


run_lfmm <- function(gen, gsd_df, adaptive_loci, K){
  #get adaptive loci
  neutral_loci <- c(1:nloci)[-adaptive_loci]
  
  #PCA to determine number of latent factors
  pc <- prcomp(gen)
  
  #gen matrix
  genmat = as.matrix(gen)
  #env matrix
  env1mat = as.matrix(gsd_df$tmp)
  
  #ENV1
  #run model
  lfmm_mod <- lfmm_ridge(genmat, env1mat, K = K)
  #performs association testing using the fitted model:
  pv <- lfmm_test(Y = genmat, 
                  X = env1mat, 
                  lfmm = lfmm_mod, 
                  calibrate = "gif")
  #adjust pvalues
  pvalues <- data.frame(env1=p.adjust(pv$calibrated.pvalue[,1], method="fdr"))
  #env1 candidate loci
  #Identify LFMM cand loci
  lfmm_loci1 <- which(pvalues[,1] < 0.05) 
  #calc True Positive Rate
  TP <- sum(lfmm_loci1 %in% adaptive_loci)
  TPR1 <- TP/length(adaptive_loci)
  #calc False Discovery Rate 
  FD <- sum(lfmm_loci1 %in% neutral_loci) 
  FDR1 <-FD/(FD + TP)
  
  return(data.frame(K = K,
                    TPR1 = TPR1, FDR1 = FDR1))
}



#register cores
cores <- detectCores()
cl <- makeCluster(cores[1]-3) #not to overload your computer
registerDoParallel(cl)

system.time(
res_lfmm <- foreach(i=1:nrow(params), .combine=rbind) %dopar% {
    
  
    #run model on full data set
    full_result <- run_lfmm_full(gen, gsd_df, loci_df)
    result <- data.frame(params[i,], sampstrat = "full", nsamp = 2000, full_result)
    
    #write full datafile (temp)
    csv_file <- paste0("outputs/LFMM_results_yosemite.csv")
    write.csv(result, csv_file, row.names = FALSE)
    
    for(nsamp in npts){
      for(sampstrat in sampstrats){
        #subsample from data based on sampling strategy and number of samples
        subIDs <- read.csv(paste0("outputs/samples_", sampstrat, nsamp, ".csv"))
        
        #remove parameter columns and convert to vector of IDs
        subIDs <- as.character(unlist(subIDs))
        subgen <- gen[subIDs,]
        subgsd_df <- gsd_df[subIDs,]
        
        #run analysis using subsample
        sub_result <- run_lfmm(subgen, subgsd_df, adaptive_loci, K = K)
        
        #save and format new result
        sub_result <- data.frame(sampstrat = sampstrat, nsamp = nsamp, sub_result)
        
        #export data to csv (temp)
        csv_df <- read.csv(csv_file)
        csv_df <- rbind(csv_df, sub_result)
        write.csv(csv_df, csv_file, row.names = FALSE)
        
        #bind results
        result <- rbind.data.frame(result, sub_result)
      }
    }
  
  #end pdf()
  dev.off()
  
  return(result)
  
  gc()
}
)

#stop cluster
stopCluster(cl)

write.csv(res_lfmm, "outputs/LFMM/lfmm_results.csv", row.names = FALSE)
```
```{r}
ggplot(result[result$sampstrat != "full",], aes(factor(nsamp), sampstrat)) +
      ggtitle("Yosemite") +
      geom_tile(aes(fill = TPR1)) + 
      geom_text(aes(label = round(TPR1, digits = 2), hjust = 0.5), size = 5) +
      scale_fill_viridis(limits=c(0, 1), option = "plasma") +
      theme_bw() +
      theme(panel.border = element_blank(), panel.grid.major = element_blank(), 
            panel.grid.minor = element_blank(), legend.position = "none",
            axis.title.x=element_blank(), axis.ticks.x=element_blank(),
            axis.title.y=element_blank(), axis.ticks.y=element_blank(),
            axis.text.x = element_text(color = "grey50", size = 18),
            axis.text.y = element_text(color = "gray50", size = 18),
            plot.title = element_text(size=20),
            plot.margin=unit(rep(0.4,4),"cm")) +
      coord_fixed()
```

