---
title: "Supplementary File 3: IBD and IBE Results"
output: 
  html_document:
    toc: true
---

```{r, warning=FALSE, include = FALSE, message = FALSE, results = 'asis', fig.width = 21, fig.height = 13}
library("here")
library("sjPlot")
library("tidyverse")
library("lme4")
library("viridis")
library("lmerTest")
library("ggplot2")
library("gridExtra")
library("grid")
library("gt")
library("ggthemes")
library("ggpubr")

source(here("p4_analysis", "analysis_functions.R"))

p4path <- here("p4_analysis", "outputs")
p3path <- here("p3_methods", "outputs")

knitr::opts_chunk$set(echo = FALSE, cache = TRUE, warning = FALSE, results = FALSE, message = FALSE)
```

***

<font size="5"> **Notes:** </font> 

**Summary plots** - Sample strategy is on the y-axis and number of sites is on the x-axis. Each plot is paired by parameter level vertically and the values in the cells are the mean value across all of the simulations for that parameter level. Note that each average encompasses all of the other varying simulation parameters.

**Full plots** - Sample strategy is on the y-axis and number of sites is on the x-axis. Each plot represents a unique simulation and the values in the cells are the mean value across all of the 10 iterations of that simulation across all three unique landscape seeds (i.e., all three sets of Neutral Landscape Models) for a total of 30 replicates. For these plots: K = population size (not to be confused with the number of latent factors (K)), phi = selection strength, m = migration, H = spatial autocorrelation, r = correlation between environmental layers.

**RAE** - Ratio Absolute Error - is the absolute difference between the observed and expected estimate of the ratio of IBE to IBD (i.e. the coefficient of IBE divided by the coefficient of IBD)

**Bias** - bias was calculated by taking the mean difference between the observed and expected coefficients or ratios

***

# 1. MMRR

## 1.1 Individual sampling

### 1.1.1 Summary plots

```{r, fig.width=14, fig.height=7}
mmrr_ind <- format_mmrr(here(p3path, "mmrr_indsampling_results.csv"))

# overall error
mmrr_gdm_plotter(mmrr_ind, "ratio_ae", colpal = "viridis", direction = -1)

# bias
mmrr_gdm_plotter(mmrr_ind, "ratio_err", divergent = TRUE)
mmrr_gdm_plotter(mmrr_ind, "comboenv_err", divergent = TRUE)
mmrr_gdm_plotter(mmrr_ind, "geo_err", divergent = TRUE)
```

### 1.1.2 Linear mixed effects models

<font size="4.5"> **RAE** </font> 

```{r, , message = FALSE, results = 'asis'}
run_lmer(mmrr_ind, "ratio_ae", filepath = here(p4path, "MMRR_individual_RAE.csv"))
```

### 1.1.3 Full plots

<font size="4.5"> **RAE** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_ind, "ratio_ae", colpal = "viridis", direction = -1)
```

<font size="4.5"> **Ratio Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_ind, "ratio_err", colpal = "viridis", divergent = TRUE)
```

<font size="4.5"> **IBD Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_ind, "geo_err", divergent = TRUE)
```

<font size="4.5"> **IBE Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_ind, "comboenv_err", divergent = TRUE)
```


## 1.2 Site sampling

### 1.2.1 Summary plots

```{r, fig.width=14, fig.height=7}
mmrr_site <- format_mmrr(here(p3path, "mmrr_sitesampling_results.csv"))

# overall error
mmrr_gdm_plotter(mmrr_site, "ratio_ae", colpal = "viridis", direction = -1)

# bias
mmrr_gdm_plotter(mmrr_site, "ratio_err", divergent = TRUE)
mmrr_gdm_plotter(mmrr_site, "comboenv_err", divergent = TRUE)
mmrr_gdm_plotter(mmrr_site, "geo_err", divergent = TRUE)
```

### 1.2.2 Linear mixed effects models

<font size="4.5"> **RAE** </font> 

```{r, , message = FALSE, results = 'asis'}
run_lmer(mmrr_site, "ratio_ae", filepath = here(p4path, "MMRR_site_RAE.csv"))
```

### 1.2.3 Full plots

<font size="4.5"> **RAE** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_site, "ratio_ae", colpal = "viridis", direction = -1)
```

<font size="4.5"> **Ratio Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_site, "ratio_err", colpal = "viridis", divergent = TRUE)
```

<font size="4.5"> **IBD Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_site, "geo_err", divergent = TRUE)
```

<font size="4.5"> **IBE Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(mmrr_site, "comboenv_err", divergent = TRUE)
```

# 2. GDM

## 2.1 Individual sampling

### 2.1.1 Summary plots

```{r, fig.width=14, fig.height=7}
gdm_ind <- format_gdm(here(p3path, "gdm_indsampling_results.csv"))

# overall error
mmrr_gdm_plotter(gdm_ind, "ratio_ae", colpal = "viridis", direction = -1)

# bias
mmrr_gdm_plotter(gdm_ind, "ratio_err", divergent = TRUE)
mmrr_gdm_plotter(gdm_ind, "comboenv_err", divergent = TRUE)
mmrr_gdm_plotter(gdm_ind, "geo_err", divergent = TRUE)
```

### 2.1.2 Linear mixed effects models

<font size="4.5"> **RAE** </font> 

```{r, , message = FALSE, results = 'asis'}
run_lmer(gdm_ind, "ratio_ae", filepath = here(p4path, "GDM_individual_RAE.csv"))
```

### 2.1.3 Full plots

<font size="4.5"> **RAE** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_ind, "ratio_ae", colpal = "viridis", direction = -1)
```

<font size="4.5"> **Ratio Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_ind, "ratio_err", divergent = TRUE)
```

<font size="4.5"> **IBD Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_ind, "geo_err", divergent = TRUE)
```

<font size="4.5"> **IBE Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_ind, "geo_err", divergent = TRUE)
```

### 2.1.4 Failed fits

*Occasionally GDM fails to fit a model, in which case an NA value is assigned. Here we visualize the proportion of NAs (i.e., cases of failed fit) across the simulations:*

<font size="4.5"> **Proportion of failed models:** </font> 
```{r,  fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_ind, "geo_coeff", aggfunc = "prop_na", colpal = "mako")
```

## 2.2 Site sampling

### 2.2.1 Summary plots

```{r, fig.width=14, fig.height=7}
gdm_site <- format_gdm(here(p3path, "gdm_sitesampling_results.csv"))

# overall error
mmrr_gdm_plotter(gdm_site, "ratio_ae", colpal = "viridis", direction = -1)

# bias
mmrr_gdm_plotter(gdm_site, "ratio_err", divergent = TRUE)
mmrr_gdm_plotter(gdm_site, "comboenv_err", divergent = TRUE)
mmrr_gdm_plotter(gdm_site, "geo_err", divergent = TRUE)
```

### 2.2.2 Linear mixed effects models

<font size="4.5"> **RAE** </font> 
```{r, , message = FALSE, results = 'asis'}
run_lmer(gdm_site, "ratio_ae", filepath = here(p4path, "GDM_site_RAE.csv"))
```

### 2.2.3 Full plots

<font size="4.5"> **RAE** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_site, "ratio_ae", colpal = "viridis", direction = -1)
```

<font size="4.5"> **Ratio Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_site, "ratio_err", divergent = TRUE)
```

<font size="4.5"> **IBD Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_site, "geo_err", divergent = TRUE)
```

<font size="4.5"> **IBE Bias** </font> 

```{r, fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_site, "geo_err", divergent = TRUE)
```

### 2.2.4 Failed fits

*Occasionally GDM fails to fit a model, in which case an NA value is assigned. Here we visualize the proportion of NAs (i.e., cases of failed fit) across the simulations:*

<font size="4.5"> **Proportion of failed models:** </font> 

```{r,  fig.width = 21, fig.height = 13}
MEGAPLOT(gdm_site, "geo_coeff", aggfunc = "prop_na", colpal = "mako")
```


```{r, eval = FALSE, fig.width=12, fig.height=11}
# Figures
arrange_figures(gdm_ind, mmrr_ind, "RAE",
                "A. GDM", "B. MMRR",
                colpal = "viridis", direction = -1, dig = 2, maxv = 0.21, minv = 0.03)

arrange_figures(gdm_site, mmrr_site, "RAE", 
                "A. GDM", "B. MMRR",
                colpal = "viridis", direction = -1, dig = 2, maxv = 0.3, minv = 0.07)
```


```{r, fig.width = 6, fig.height = 6}
results <- list(mmrr_ind, mmrr_site, gdm_ind, gdm_site)

filt_results <- map(results,  ~filter(.x, phi == 0.5, H == 0.5, m == 1.00, r == 0.3, K == 2))

sub_results <- map(filt_results, \(x){
   x <- 
     x %>%
     group_by(nsamp, sampstrat) %>%
     summarize(RAE = mean(RAE, na.rm = TRUE), 
               ratio_err = mean(ratio_err, na.rm = TRUE), 
               env_err = mean(comboenv_err, na.rm = TRUE),
               geo_err = mean(geo_err, na.rm = TRUE),
               .groups = "keep") %>%
     rename(Bias = ratio_err)
   
   stopifnot(nrow(x) == 16 | nrow(x) == 9)
                    
   return(x)
})

RAE_plots <- map(sub_results, heat_plot, stat_name = "RAE", maxv = 0.31, minv = 0.04, 
                 colpal = "viridis", direction = -1)

ratio_err_plots <- map(sub_results, heat_plot, stat_name = "Bias", divergent = TRUE,
                       minv = -0.06, maxv = 0.30)

RAE_ind <- ggarrange(RAE_plots[[1]], RAE_plots[[3]], common.legend = TRUE, nrow = 1, legend = "none")
ERR_ind <- ggarrange(ratio_err_plots[[1]], ratio_err_plots[[3]], common.legend = TRUE, nrow = 1, legend = "none")

RAE_site <- ggarrange(RAE_plots[[2]], RAE_plots[[4]], common.legend = TRUE, nrow = 1, legend = "none")
ERR_site <- ggarrange(ratio_err_plots[[2]], ratio_err_plots[[4]], common.legend = TRUE, nrow = 1, legend = "none")

pdf(here("plots", "IBDIBE_ind.pdf"))
ggarrange(RAE_ind, ERR_ind, nrow = 2, align = "h")
ggarrange(RAE_site, ERR_site, nrow = 2, align = "h")

pdf(here("plots", "IBDIBE_ind.pdf"))
ggarrange(RAE_ind, ERR_ind, nrow = 2, align = "h")
dev.off()

pdf(here("plots", "IBDIBE_site.pdf"))
ggarrange(RAE_site, ERR_site, nrow = 2, align = "h")
dev.off()

pdf(here("plots", "IBDIBE_RAE_legend.pdf"))
ggarrange(RAE_plots[[1]], common.legend = TRUE, nrow = 1, legend = "right")
dev.off()

pdf(here("plots", "IBDIBE_RE_legend.pdf"))
ggarrange(ratio_err_plots[[1]], common.legend = TRUE, nrow = 1, legend = "right")
dev.off()
```

NOTES: 
- problem: inferences across all simulations are different from that of a single simulation
- average across all simulation also don't make sense
- but we care about what is true across them all in some sense because that is the info we can go off of, not the "best case scenario" - however the average of them all assumes that the simulations cover all of parameter space as a meaningful summary
- fuck i don't care about any of this
- what is significant varies based on sample size - sample size is treated as continuous
- do I need to run more simulations to get more power?


- NOTE: figure out how to describe bias patter (underestimation for grid only occurs under certain scenarios)